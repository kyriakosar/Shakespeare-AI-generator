{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import re\n",
    "import pronouncing as pr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Poem:\n",
      "Let him when my vows are sweetest bud. unswept stone,\n",
      "Can make faults, and owners of one hour\n",
      "Of faults thy humour doth well beseem thy face should\n",
      "To show it was builded far the fragrant rose, in\n",
      "That heavy sleep a joy above that one\n",
      "And ruin'd choirs, where your trespass now\n",
      "But then ten times happy are restor'd and tombs\n",
      "That sometimes anger thrusts into my\n",
      "And almost thence this title do forgive\n",
      "Save breed, to ruinate vowing new pay as they grew?\n",
      "And simple truth miscall'd simplicity, world\n",
      "But beauty's veil doth she quenched in thee a\n",
      "Save what conscience is partly blind, be blessed\n",
      "For it were to wet a look,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the URL to fetch poems\n",
    "url = \"https://poetrydb.org/author,title/Shakespeare;Sonnet\"\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    poems = response.json()\n",
    "    poem_lines = [line for poem in poems for line in poem['lines']]\n",
    "else:\n",
    "    print(\"Failed to fetch poems.\")\n",
    "\n",
    "def count_syllables(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub('[^a-z]+', ' ', text.lower())\n",
    "    phones = [pr.phones_for_word(p)[0] for p in text.split() if pr.phones_for_word(p)]\n",
    "    syllable_count = sum([pr.syllable_count(p) for p in phones])\n",
    "\n",
    "    return syllable_count\n",
    "\n",
    "\n",
    "def preprocess_verse(verse):\n",
    "    \"\"\"Lowercase and filter all punctuation\"\"\"\n",
    "    # Lowercase\n",
    "    verse_lower = verse.strip().lower()\n",
    "    # Filter punctuation (keep numbers)\n",
    "    return re.sub('[^a-z \\d]+', '', verse_lower)\n",
    "\n",
    "def last_word(verse):\n",
    "    \"\"\"Retrieve the last word of a verse\"\"\"\n",
    "    return preprocess_verse(verse).split()[-1]\n",
    "\n",
    "def verse_rhyme(verse):\n",
    "    \"\"\"Gets the rhyme of a verse\"\"\"\n",
    "    # Get the last word\n",
    "    w = last_word(verse)\n",
    "    # Get the last two phones\n",
    "    phones = pr.phones_for_word(w)\n",
    "    if phones:\n",
    "        last = re.match('.+ ([a-zA-Z]+[0-9][^0-9]*)$', phones[0])\n",
    "        if last:\n",
    "            rhyme = last.group(1)\n",
    "            return rhyme\n",
    "        else:\n",
    "            return phones[0]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def generate_line(markov_model, max_syllables=11):\n",
    "    line = []\n",
    "    current_word = random.choice(markov_model[\"__start__\"])\n",
    "    line.append(current_word)\n",
    "    syllable_count = count_syllables(current_word)\n",
    "\n",
    "    while syllable_count < max_syllables:\n",
    "        \n",
    "        if current_word == \"__end__\":\n",
    "            break\n",
    "\n",
    "        next_words = markov_model.get(current_word, {\"next_word\": [\"__end__\"], \"probabilities\": [1.0]})\n",
    "        \n",
    "        valid_next_words = [word for word, prob in zip(next_words[\"next_word\"], next_words[\"probabilities\"]) if syllable_count + count_syllables(word) <= max_syllables]\n",
    "        \n",
    "        if not valid_next_words:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "        next_word = random.choice(valid_next_words)\n",
    "\n",
    "        while next_word == \"__end__\":\n",
    "            current_word = random.choice(markov_model[\"__start__\"])\n",
    "            next_words = markov_model.get(current_word, {\"next_word\": [\"__end__\"], \"probabilities\": [1.0]})\n",
    "            valid_next_words = [word for word, prob in zip(next_words[\"next_word\"], next_words[\"probabilities\"]) if syllable_count + count_syllables(word) <= max_syllables]\n",
    "            if not valid_next_words:\n",
    "                break\n",
    "            next_word = random.choice(valid_next_words)\n",
    "\n",
    "        \n",
    "        line.append(next_word)\n",
    "        current_word = next_word\n",
    "        syllable_count += count_syllables(next_word)\n",
    "\n",
    "    return \" \".join(line[:-1])\n",
    "\n",
    "\n",
    "# # Function to generate a poem with multiple lines\n",
    "def generate_poem(markov_model, line_count=14):\n",
    "    poem = []\n",
    "    for _ in range(line_count):\n",
    "        line = generate_line(markov_model)\n",
    "        poem.append(line)\n",
    "\n",
    "    return \"\\n\".join(poem)\n",
    "\n",
    "def generate_poem(markov_model, line_count=14, max_syllables=11):\n",
    "    poem = []\n",
    "    for _ in range(line_count):\n",
    "        line = generate_line(markov_model)\n",
    "        poem.append(line)\n",
    "\n",
    "    return \"\\n\".join(poem)\n",
    "\n",
    "\n",
    "# Function to build a Markov chain model from a list of lines with probabilities\n",
    "def build_markov_model(lines):\n",
    "    markov_model = {\"__start__\": [], \"__end__\": []}\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        markov_model[\"__start__\"].append(words[0])\n",
    "        markov_model[\"__end__\"].append(words[-1])\n",
    "\n",
    "        for i in range(len(words) - 1):\n",
    "            current_word = words[i]\n",
    "            next_word = words[i + 1]\n",
    "\n",
    "            if current_word not in markov_model:\n",
    "                markov_model[current_word] = {\"next_word\": [], \"probabilities\": []}\n",
    "\n",
    "            markov_model[current_word][\"next_word\"].append(next_word)\n",
    "\n",
    "    for word in markov_model:\n",
    "        if word not in [\"__start__\", \"__end__\"]:\n",
    "            next_words = markov_model[word][\"next_word\"]\n",
    "            word_count = len(next_words)\n",
    "            next_word_set = list(set(next_words))  # Remove duplicates\n",
    "            probabilities = [next_words.count(word) / word_count for word in next_word_set]\n",
    "            markov_model[word][\"next_word\"] = next_word_set\n",
    "            markov_model[word][\"probabilities\"] = probabilities\n",
    "\n",
    "    return markov_model\n",
    "\n",
    "\n",
    "# Build a Markov chain model from the list of lines\n",
    "markov_model = build_markov_model(poem_lines)\n",
    "\n",
    "# Generate a new poem with multiple lines\n",
    "new_poem = generate_poem(markov_model, line_count=14)\n",
    "\n",
    "print(\"Generated Poem:\")\n",
    "print(new_poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
